<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Ethical Intelligence - articles</title><link href="/" rel="alternate"></link><link href="/feeds/articles.atom.xml" rel="self"></link><id>/</id><updated>2020-01-08T07:20:00+01:00</updated><entry><title>Tweeting from the Afterlife: Exploring the Deaths of Social Network Members and the Birth of Online Remembrance</title><link href="/tweeting-from-the-afterlife.html" rel="alternate"></link><published>2020-01-08T07:20:00+01:00</published><updated>2020-01-08T07:20:00+01:00</updated><author><name>Robert Seddon</name></author><id>tag:None,2020-01-08:/tweeting-from-the-afterlife.html</id><summary type="html">&lt;p&gt;Tweeting from the Afterlife: Exploring the Deaths of Social Network Members and the Birth of Online Remembrance&lt;/p&gt;</summary><content type="html">&lt;p&gt;Social networks such as Twitter and Facebook are frequent targets of criticism for handling personal data in ways that undermine the privacy and dignity of their users. Twitter recently found itself in the unusual position of receiving criticism for an effort to protect the privacy of user data, by announcing plans to initiate a cull of abandoned accounts on December 11 2019 as part of an effort to comply with EU data privacy regulations.&lt;/p&gt;
&lt;p&gt;Who would miss accounts that had been disused for ages? Quite a few people, it turned out. It wasn’t because lapsed users thought they might start using their accounts again. The accounts most at stake will never tweet again, because they fell silent when their owners died.&lt;/p&gt;
&lt;p&gt;By leaving their thoughts behind on the social network, people had created a presence for themselves that persisted long after death. Twitter suddenly faced objections from people who would visit the preserved thoughts of a departed &lt;a href="https://www.inc.com/jason-aten/twitter-said-it-would-delete-unused-accounts-then-it-realized-some-of-them-belong-to-people-we-want-to-remember.html"&gt;father&lt;/a&gt;, &lt;a href="https://www.bbc.co.uk/news/newsbeat-50584688"&gt;boyfriend&lt;/a&gt; or other loved ones.&lt;/p&gt;
&lt;p&gt;For a site that promotes itself as the place to go to discover ‘what’s happening in the world and what people are talking about right now’ this came as a surprise. In fact, it highlights one of the significant changes in online culture since use of the Internet became widespread. A decade ago, Friendster was a major social network, but usage declined until the site eventually closed, an event foreshadowed by an article in the satirical publication The Onion, which &lt;a href="https://www.theonion.com/internet-archaeologists-find-ruins-of-friendster-civili-1819594871"&gt;spoofed Friendster&lt;/a&gt; as an archaeological site marking a lost civilisation. Abandoned accounts on a social network aren’t just a liability, they reflect the health of the platform, and can be an undesirable signal that platforms might wish to conceal. It’s very natural for a business to value current and potential customers, and lost customers that might yet be regained, but much less to value those that are deceased. How should a social network value users that can no longer use its product? &lt;/p&gt;
&lt;h2&gt;Read-Only Memorials&lt;/h2&gt;
&lt;p&gt;As more and more of us have started living significant parts of our lives online, however, an increasing amount of the content on social platforms has been created by people who are no longer alive. Because of this, we can all expect to have ‘digital afterlives’.&lt;/p&gt;
&lt;p&gt;The sheer scale is remarkable. Take Facebook as an example, which already has a memorialisation feature for deceased users. &lt;a href="https://journals.sagepub.com/doi/full/10.1177/2053951719842540"&gt;Carl Öhman and David Watson project&lt;/a&gt; that billions of Facebook users will have passed away before 2100, by which time ‘the dead may well outnumber the living’. Öhman’s research with Luciano Floridi examines a whole &lt;a href="https://link.springer.com/article/10.1007/s11023-017-9445-2"&gt;digital afterlife industry&lt;/a&gt; dealing with &lt;a href="https://ora.ox.ac.uk/objects/uuid:c059841d-a702-4218-8c1b-39ff49dc6c65/download_file?safe_filename=Ohman_Floridi_R1_edited.pdf&amp;amp;file_format=application%252Fpdf&amp;amp;type_of_work=Journal+article"&gt;online remains&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Firms such as Eterni.me and Replica now offer consumers online chat bots, based on one’s digital footprint, which continue to live on after users die, enabling the bereaved to “stay in touch” with the deceased. This new phenomenon has opened up opportunities for commercial enterprises to monetise the digital afterlife of Internet users. As a consequence the economic interests of these firms are increasingly shaping the presence of the online dead.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In large part this is about how those still living can be helped to feel better and cope with loss—and that’s no small thing. Technology can honour the past as well as building the future. When London’s underground railway upgraded its automatic announcement system, in the process replacing the old ‘Mind the gap’ recording, it emerged that the actor who made it had left behind a widow who still listened for her husband’s voice at her station. Railway staff worked to digitise and restore the recording, securing emotional succour for one woman and over &lt;a href="https://twitter.com/garius/status/1204795961731629058"&gt;forty thousand likes on Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Another form of benefit for those still living can come from the rich historical resource which all these online posters have cumulatively created. Öhman and Watson emphasise this aspect, describing the aggregate contributions of social media users as a form of cultural heritage which is of value both to historians and ‘to future generations as part of their record and self-understanding’. They advocate ‘a multi-stakeholder approach’ to the maintenance of this record: a commercial platform like Facebook has an obvious economic interest in the running of its own services, but other interested parties might include ‘states, NGOs, universities, libraries, museums’ and the like. Historic data might someday be handled like historic buildings, as assets that come with special responsibilities for their owners.&lt;/p&gt;
&lt;h2&gt;Mortal Obligations?&lt;/h2&gt;
&lt;p&gt;To say that preserving data of this sort benefits the living, however, isn’t to say that we should understand the value of their digital artifacts entirely in relation to the interests of living people’s wants and needs. [see in reply] We may care not only about doing good for the living, but also about doing the rightly respectful thing for the departed themselves.&lt;/p&gt;
&lt;p&gt;If we believe they are departed, though, to either oblivion or an otherworldly afterlife, then we may be perplexed about how we might be able to treat them well or badly: how they could be, in the philosophical jargon, moral patients. Explanations we might give for moral responsibilities towards sentient beings—explanations involving the capacity to suffer, for example—seem doubtfully applicable towards those who have gone to rest in peace.&lt;/p&gt;
&lt;p&gt;The problem isn’t that we can’t conceive of how there could be any kind of moral patient besides a living, thinking, feeling being. Some philosophers do believe there are other kinds of moral patient, and quite possibly you do as well: if you care about ‘the environment’ then you care for something that, though it incorporates various kinds of sentient organism, isn’t reducible to any of them. The problem is that the conceptual toolkit I’d use in asking, say, what could be wrong with wantonly destroying a fossilised ammonite isn’t a toolkit one can simply go ahead and apply to things left behind by human beings. We don’t relate to that long-dead organism as we do to a dead person.&lt;/p&gt;
&lt;p&gt;So questions are explored about what could make dead people, as a class, qualify as moral patients. Is it possible to harm the dead? Do practices like writing and honouring wills imply that obligations towards the dead person who is are disguised duties to the living one who was, or does that merely restate the paradox in another form?&lt;/p&gt;
&lt;h2&gt;Social Media Absence&lt;/h2&gt;
&lt;p&gt;Twitter was forced to consider dead people as a class among its account-holders, but that’s because of some users’ very specific connections with particular people they’ve lost: with parents and spouses and lovers and friends, people with names and personal histories. Parts of those individual histories linger online. When we remember people through mementos—a portrait, say—our treatment of the objects expresses attitudes towards the people themselves. If you see a social media profile in this way, like a portrait you’d hang in a place of honour, then the point of view from which it’s obsolete clutter in the database is going to be far from what you can personally endorse.&lt;/p&gt;
&lt;p&gt;Öhman and Floridi suggest that we should literally regard the digital material people leave behind as a form of human remains—‘not merely regarded as a chattel or an estate, but as something constitutive of one’s personhood’—and should draw on archaeological ethics to identify the principles behind respectful display of them. It’s unclear how far existing archaeological ethics will take us towards working out whether anyone has an obligation to fund the ongoing display, however; the Internet has nothing analogous to reburial.&lt;/p&gt;
&lt;p&gt;Some writers on the ethics of heritage and human remains contrast a materialist, empiricist West, which thinks of being dead as being gone, with different societies in which the dead are understood to have an ongoing presence in the life of a community. &lt;a href="http://www.piotrbienkowski.co.uk/"&gt;Piotr Bienkowski&lt;/a&gt;, for example, has written that scepticism about connections with people from former times arises from a view of the world that regards the dead ‘as no longer existing or having personhood in any sense’. If that’s how the West truly thinks, though, then perhaps our technological society is developing so that we start to think differently.&lt;/p&gt;
&lt;p&gt;It is now common for some of our most significant relationships to take place entirely online. If we encounter people through their online presence while they live to update it, maybe it’s not so strange a notion that something of them remains present while it persists on the servers. We should bear in mind, though, that for many people, their  online personae are not authoritative self-portraitures but often impressionistic or playful takes on themselves, sometimes multiple masques that relate only part of their personalities to specific audiences. We should perhaps be careful about these subtleties when memorializing online self-expression, and not take it more seriously in death than the mind behind it did in life. Nevertheless, even an outright parody account can be fondly regarded as part of a community. It leaves a hole in that community when the posting suddenly ceases, and can retain its place of honour in the ‘social graph’ of friend or follower relationships.&lt;/p&gt;
&lt;h2&gt;Last Words&lt;/h2&gt;
&lt;p&gt;In ten years we’ve gone from seeing Friendster’s decline spoofed as an archaeological dig to Öhman and Watson’s serious proposal that Internet hosts are custodians of a form of human cultural heritage. And as stories about bereavement go, Twitter’s experience carries a heartwarming moral: what seemed to be a load of disused data was in fact a memorial to the dead and is actually giving living people reasons to keep coming back to the site.&lt;/p&gt;
&lt;p&gt;Twitter was taken aback by the discovery that deceased people can still be part of its community. This is not the only form online remembrance can take—you may even have had a secret memorial sent to you in &lt;a href="https://xclacksoverhead.org/home/about"&gt;HTTP headers&lt;/a&gt; — but it’s a form that underlines how those content posters who’ve passed on can still have significant social and therefore ethical relationships with living people: relationships that matter to those people in ways that foster a deep commitment to keeping them going.&lt;/p&gt;
&lt;p&gt;Digital afterlives are a recent and growing source of questions for industry and policy—and Twitter will still be working out how best to square them with EU privacy rules. These are the early stages of working out how to handle personal grief on the public Internet: who shall bear the costs, and when it’s acceptable for the ‘digital afterlife industry’ to explore the opportunities. Will this lead to the involvement of religious bodies, such as the Vatican, when it comes to the preservation of digital afterlives? For tech companies already under the spotlight, approaching these questions with ethical sensitivity will be part of securing their own survival. For regulators and ethicists, this is an important issue that problematises recent approaches to privacy and data rights. &lt;/p&gt;</content><category term="articles"></category><category term="ethics"></category></entry><entry><title>Falsehoods Programmers Believe About Ethics</title><link href="/falsehoods-programmers-believe-about-ethics.html" rel="alternate"></link><published>2019-12-02T07:20:00+01:00</published><updated>2019-12-02T07:20:00+01:00</updated><author><name>Olivia Gambelin</name></author><id>tag:None,2019-12-02:/falsehoods-programmers-believe-about-ethics.html</id><summary type="html">&lt;p&gt;Some thoughts about the interface between programmers and tech ethics.&lt;/p&gt;</summary><content type="html">&lt;p&gt;As a Tech Ethicist, I come into contact with programmers almost daily, as my work requires me to navigate the technical objectives and implementation details in addition to the ethical dimensions of the projects I analyze. Through these experiences, I’ve found myself having some of the same conversations over and over, all surrounding the applicability of ethics in the tech industry. There are some persistent misconceptions about both the study of ethics and its application to technical work. In order to help bring clarity to the confusion surrounding ethics in tech, I’m going to briefly discuss three significant misconceptions I've observed. &lt;/p&gt;
&lt;h2&gt;There is one right answer &lt;br /&gt; &lt;em&gt;(or no right answers, if you take a subjective approach)&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Ethics is the study of right and wrong, so shouldn’t there be a right and wrong answer to every ethical question? If there was, then the ethical dilemmas programers and technologists face would have long been answered by general principles with universal applicability across projects, cultures, and domains. Of course, if this were true, the daily news would not include so many stories involving ethical lapses or miscalculations where technological platforms, tools, and solutions cause serious harms. We are all familiar with the headline stories, self-driving cars making errors that human drivers would not, autonomous weapons systems being developed and deployed by militaries, banks and governments using AI driven gatekeepers to control access to credit and social services, and fintech companies making trading decisions at the speed of light, far faster than humans can intervene. These are all headline worthy examples of tech gone wrong due to ethical lapses. But, when we take a step back from these bigger stories, we also discover the points in which software engineers and technologists are at risk for the same ethical lapses, as they make decisions every day in the course of their work that can have real ethical impacts. ‘Do I use a social sign-on SDK, because it’s faster, even though there are privacy tradeoffs? Do we let a test suite languish to save time? Do we optimize for the biggest curve, even if that means missing important edge cases? Is the dataset we are pre-training an algorithm with fair, and ethically sourced?’&lt;/p&gt;
&lt;p&gt;It might seem like there are only two possible solutions to these ethical dilemmas. Either we finally discover this elusive single, straightforward, universal guideline that can be applied across the board, or, if that doesn’t exist, then we must throw up our hands in defeat because ethics is too subjective and we will never arrive at an acceptable single answer.  Why is it that these seem to be our only two possible solutions to solving tech ethics problems? Well, we all come from different backgrounds, which in turn shape our understanding of what constitutes right and wrong. Everything from our culture, our education, and our life experiences can potentially influence how we approach ethical problems. Because of this, being aware of, and finding solutions to the ethical dilemmas raised by technology requires careful navigation of the multiple understandings of right and wrong at play. To complicate matters further, ethics is an emotionally charged topic. We are very attached to our personal ethical frameworks, and are hurt when it is threatened or violated. And yet, there are situations in which two people can have opposing ethical frameworks, and still both arrive at what could be considered a right answer in accordance to those individual frameworks.  The combination of this emotional attachment along with the varying ethical frameworks results in the feeling that the right answer to our ethical dilemmas is impossible to find. &lt;/p&gt;
&lt;p&gt;However, I would argue otherwise, as there are significant overlaps in the ethical frameworks between individuals. This overlap in turn enables us to uncover an understanding of the problems we face and from there make informed decisions. What I'm suggesting is that we don't need to solve the fundamental metaethical dilemmas that philosophers have been arguing about for millennia in order to appreciate and mitigate the ethical risks that technical decisions expose us to. Often an informed ethical awareness is the most significant step towards improving our ability to foresee and to mitigate the ethical risks in our technical practices. &lt;/p&gt;
&lt;h2&gt;It is possible to eliminate ethical bias&lt;/h2&gt;
&lt;p&gt;Algorithmic bias has become a buzzword with a strong negative connotation which results in  often hearing that we need to eliminate bias in our algorithms. However, when it comes to bias in terms of ethical decision making, it is not actually possible to completely eliminate that bias. This is because data is not neutral, it reproduces the biases in the world it comes from, as well as new biases introduced knowingly or accidentally through collection, processing and use. When we try to mitigate bias in data, we must often confront real ethical dilemmas from the world it came from, and make our best efforts to address them. Confronting these dilemmas, or, in other words, attempting to mitigate the biases inherent in the data, involves taking a stance of our own, which is a sort of bias itself. So, in this sense, ethical bias is impossible to fully eliminate, which makes it something we should take on as a serious responsibility.&lt;/p&gt;
&lt;p&gt;Let’s explore this. You’re working for a university, collecting simple data on students such as class attendance, grades, library usage, when you’re asked to develop specific insight on student mental health out of this data. You of course know to clean the data and set controls to mitigate any previous biases as a first step. However, in order to move on to creating the algorithm that will allow you to draw insights into the mental health status of students, you must first take a biased stance on ethics. You either have to decide to create an algorithm that will track student mental health with the hopes of providing care and wellbeing for the greatest amount of people, or decide that this would be a violation of respecting the dignity of an individual, and so not create the algorithm.  In other words, your decision between the two equally as important ethical values depends on your own bias towards those values. Since there is no way to honor both values equally in this situation, a decision must be taken by prioritizing one value over the other, and the ethical bias cannot be avoided. It is also important to note that in this example, the ethical dilemma surfaces only after the info from the data is extracted. By extracting this knowledge on the mental status of students, an ethical imperative to help the identified students is created. This all goes to show, collecting knowledge from datasets is not an ethically neutral task. 
Programmers need to be acutely aware of what ethical values are at play and how they are prone to prioritize these values. It's easy to get lost in the weeds solving architectural and implementation problems, but even these ground level decisions can have ethical impacts we must be aware of. Choices of technologies, datasets, integration partners, and problem definitions all expose the ethical edges of technical development. At the macro level, it's important to take a step back, and make sure we have articulated and examined the values that have guided and shape the formulation of business and technical goals, so that the ways these values interface with other values in the world in which our systems are deployed are understood and made clear. It is therefore essential to to build this kind of ethical awareness into organizational culture and technical decision-making. &lt;/p&gt;
&lt;h2&gt;Ethics is a blocker to innovation&lt;/h2&gt;
&lt;p&gt;Is ethics someone else's problem? Surely the software’s only responsibility is to is to work, not understand ethics. This is a view I often hear when speaking with programmers, as they express an underlying fear of having constraints placed on their previously unencumbered freedom to develop their technology. Ethics can appear to be a blocker if it is viewed as just another piece of paperwork that needs to be filed or the opportunity for someone from a non-technical background who just doesn’t get ‘it’ to kill an interesting project before it’s had the chance to get off the ground. &lt;/p&gt;
&lt;p&gt;However, there’s another perspective. You can think about tech ethics in much the same way programmers are accustomed to thinking about technical debt. Making short term architectural decisions to meet immediate needs involves taking on a notion of "well, it works" that is dangerously myopic. Most programmers are intimately familiar with the exponential accumulation of technical debt, and the astounding difficulty in mitigating it, when working in an environment that doesn’t value longer term thinking. Ethics is the same way. Tiny shortcuts in seemingly insignificant systems can have real effects on people’s lives. In a recent project we looked at, a contractor working on the logged-out view of a particular web application state left in personally identifying information that could be used to unmask users in ways at risk to be that could be abused into pinpointing places and times they had attended particular events. The contractor satisfied the requirements they were given, the test suite didn’t check this, QA didn’t, and a higher level-commitment to recognizing the failure modes that mishandling the unique data this company held had never been made.&lt;/p&gt;
&lt;p&gt;Building in ethical awareness from the ground up is an asset, not a liability. If we go about developing our technology ethically, we are innovating for long-term sustainability, not short-term profit. Whereas, if we “move fast and break things”, without ethical considerations, then it is only a matter of time before consequences arise that are difficult or impossible to unwind. When we break things, people get hurt. There are financial, social, legal, and moral costs involved. Technical innovation needs ethics (and technical advancement likewise allows use to make ethical advances), because at the end of the day, we as humans try to do the right thing, and expect our technology to do the same. &lt;/p&gt;</content><category term="articles"></category><category term="ethics"></category></entry></feed>