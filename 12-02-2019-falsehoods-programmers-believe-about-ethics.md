Title: Falsehoods Programmers Believe About Ethics 
Date: 2019-12-02 07:20
Modified: 2019-12-02 07:20
Category: articles
Tags: ethics
Slug: falsehoods-programmers-believe-about-ethics 
Authors: Olivia Gambelin 
Summary: Some thoughts about the interface between programmers and tech ethics. 

As a Tech Ethicist, I come into contact with programmers almost daily, as my work requires me to navigate the technical objectives and implementation details in addition to the ethical dimensions of the projects I analyze. Through these experiences, I’ve found myself having some of the same conversations over and over, all surrounding the applicability of ethics in the tech industry. There are some persistent misconceptions about both the study of ethics and its application to technical work. In order to help bring clarity to the confusion surrounding ethics in tech, I’m going to briefly discuss three significant misconceptions I've observed. 


## There is one right answer <br /> *(or no right answers, if you take a subjective approach)*


Ethics is the study of right and wrong, so shouldn’t there be a right and wrong answer to every ethical question? If there was, then the ethical dilemmas programers and technologists face would have long been answered by general principles with universal applicability across projects, cultures, and domains. Of course, if this were true, the daily news would not include so many stories involving ethical lapses or miscalculations where technological platforms, tools, and solutions cause serious harms. We are all familiar with the headline stories, self-driving cars making errors that human drivers would not, autonomous weapons systems being developed and deployed by militaries, banks and governments using AI driven gatekeepers to control access to credit and social services, and fintech companies making trading decisions at the speed of light, far faster than humans can intervene. These are all headline worthy examples of tech gone wrong due to ethical lapses. But, when we take a step back from these bigger stories, we also discover the points in which software engineers and technologists are at risk for the same ethical lapses, as they make decisions every day in the course of their work that can have real ethical impacts. ‘Do I use a social sign-on SDK, because it’s faster, even though there are privacy tradeoffs? Do we let a test suite languish to save time? Do we optimize for the biggest curve, even if that means missing important edge cases? Is the dataset we are pre-training an algorithm with fair, and ethically sourced?’


It might seem like there are only two possible solutions to these ethical dilemmas. Either we finally discover this elusive single, straightforward, universal guideline that can be applied across the board, or, if that doesn’t exist, then we must throw up our hands in defeat because ethics is too subjective and we will never arrive at an acceptable single answer.  Why is it that these seem to be our only two possible solutions to solving tech ethics problems? Well, we all come from different backgrounds, which in turn shape our understanding of what constitutes right and wrong. Everything from our culture, our education, and our life experiences can potentially influence how we approach ethical problems. Because of this, being aware of, and finding solutions to the ethical dilemmas raised by technology requires careful navigation of the multiple understandings of right and wrong at play. To complicate matters further, ethics is an emotionally charged topic. We are very attached to our personal ethical frameworks, and are hurt when it is threatened or violated. And yet, there are situations in which two people can have opposing ethical frameworks, and still both arrive at what could be considered a right answer in accordance to those individual frameworks.  The combination of this emotional attachment along with the varying ethical frameworks results in the feeling that the right answer to our ethical dilemmas is impossible to find. 


However, I would argue otherwise, as there are significant overlaps in the ethical frameworks between individuals. This overlap in turn enables us to uncover an understanding of the problems we face and from there make informed decisions. What I'm suggesting is that we don't need to solve the fundamental metaethical dilemmas that philosophers have been arguing about for millennia in order to appreciate and mitigate the ethical risks that technical decisions expose us to. Often an informed ethical awareness is the most significant step towards improving our ability to foresee and to mitigate the ethical risks in our technical practices. 


## It is possible to eliminate ethical bias 


Algorithmic bias has become a buzzword with a strong negative connotation which results in  often hearing that we need to eliminate bias in our algorithms. However, when it comes to bias in terms of ethical decision making, it is not actually possible to completely eliminate that bias. This is because data is not neutral, it reproduces the biases in the world it comes from, as well as new biases introduced knowingly or accidentally through collection, processing and use. When we try to mitigate bias in data, we must often confront real ethical dilemmas from the world it came from, and make our best efforts to address them. Confronting these dilemmas, or, in other words, attempting to mitigate the biases inherent in the data, involves taking a stance of our own, which is a sort of bias itself. So, in this sense, ethical bias is impossible to fully eliminate, which makes it something we should take on as a serious responsibility.


Let’s explore this. You’re working for a university, collecting simple data on students such as class attendance, grades, library usage, when you’re asked to develop specific insight on student mental health out of this data. You of course know to clean the data and set controls to mitigate any previous biases as a first step. However, in order to move on to creating the algorithm that will allow you to draw insights into the mental health status of students, you must first take a biased stance on ethics. You either have to decide to create an algorithm that will track student mental health with the hopes of providing care and wellbeing for the greatest amount of people, or decide that this would be a violation of respecting the dignity of an individual, and so not create the algorithm.  In other words, your decision between the two equally as important ethical values depends on your own bias towards those values. Since there is no way to honor both values equally in this situation, a decision must be taken by prioritizing one value over the other, and the ethical bias cannot be avoided. It is also important to note that in this example, the ethical dilemma surfaces only after the info from the data is extracted. By extracting this knowledge on the mental status of students, an ethical imperative to help the identified students is created. This all goes to show, collecting knowledge from datasets is not an ethically neutral task. 
Programmers need to be acutely aware of what ethical values are at play and how they are prone to prioritize these values. It's easy to get lost in the weeds solving architectural and implementation problems, but even these ground level decisions can have ethical impacts we must be aware of. Choices of technologies, datasets, integration partners, and problem definitions all expose the ethical edges of technical development. At the macro level, it's important to take a step back, and make sure we have articulated and examined the values that have guided and shape the formulation of business and technical goals, so that the ways these values interface with other values in the world in which our systems are deployed are understood and made clear. It is therefore essential to to build this kind of ethical awareness into organizational culture and technical decision-making. 


## Ethics is a blocker to innovation 


Is ethics someone else's problem? Surely the software’s only responsibility is to is to work, not understand ethics. This is a view I often hear when speaking with programmers, as they express an underlying fear of having constraints placed on their previously unencumbered freedom to develop their technology. Ethics can appear to be a blocker if it is viewed as just another piece of paperwork that needs to be filed or the opportunity for someone from a non-technical background who just doesn’t get ‘it’ to kill an interesting project before it’s had the chance to get off the ground. 


However, there’s another perspective. You can think about tech ethics in much the same way programmers are accustomed to thinking about technical debt. Making short term architectural decisions to meet immediate needs involves taking on a notion of "well, it works" that is dangerously myopic. Most programmers are intimately familiar with the exponential accumulation of technical debt, and the astounding difficulty in mitigating it, when working in an environment that doesn’t value longer term thinking. Ethics is the same way. Tiny shortcuts in seemingly insignificant systems can have real effects on people’s lives. In a recent project we looked at, a contractor working on the logged-out view of a particular web application state left in personally identifying information that could be used to unmask users in ways at risk to be that could be abused into pinpointing places and times they had attended particular events. The contractor satisfied the requirements they were given, the test suite didn’t check this, QA didn’t, and a higher level-commitment to recognizing the failure modes that mishandling the unique data this company held had never been made.


Building in ethical awareness from the ground up is an asset, not a liability. If we go about developing our technology ethically, we are innovating for long-term sustainability, not short-term profit. Whereas, if we “move fast and break things”, without ethical considerations, then it is only a matter of time before consequences arise that are difficult or impossible to unwind. When we break things, people get hurt. There are financial, social, legal, and moral costs involved. Technical innovation needs ethics (and technical advancement likewise allows use to make ethical advances), because at the end of the day, we as humans try to do the right thing, and expect our technology to do the same. 
 

