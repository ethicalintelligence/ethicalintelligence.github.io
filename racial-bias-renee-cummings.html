<!DOCTYPE html>
<html lang="en">
<head>
        
        <link rel="apple-touch-icon" sizes="57x57" href="/extra/apple-icon-57x57.png">
        <link rel="apple-touch-icon" sizes="60x60" href="/extra/apple-icon-60x60.png">
        <link rel="apple-touch-icon" sizes="72x72" href="/extra/apple-icon-72x72.png">
        <link rel="apple-touch-icon" sizes="76x76" href="/extra/apple-icon-76x76.png">
        <link rel="apple-touch-icon" sizes="114x114" href="/extra/apple-icon-114x114.png">
        <link rel="apple-touch-icon" sizes="120x120" href="/extra/apple-icon-120x120.png">
        <link rel="apple-touch-icon" sizes="144x144" href="/extra/apple-icon-144x144.png">
        <link rel="apple-touch-icon" sizes="152x152" href="/extra/apple-icon-152x152.png">
        <link rel="apple-touch-icon" sizes="180x180" href="/extra/apple-icon-180x180.png">
        <link rel="icon" type="image/png" sizes="192x192"  href="/extra/android-icon-192x192.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/extra/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="96x96" href="/extra/favicon-96x96.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/extra/favicon-16x16.png">
        <link rel="manifest" href="/extra/manifest.json">
        <meta name="msapplication-TileColor" content="#ffffff">
        <meta name="msapplication-TileImage" content="/extra/ms-icon-144x144.png">
        <meta name="theme-color" content="#ffffff">
        
        <link href="https://fonts.googleapis.com/css?family=Oswald:400,500,600,700&display=swap" rel="stylesheet">        
        <link href="https://fonts.googleapis.com/css?family=Nunito&display=swap" rel="stylesheet">
    
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        
          <title>Ethical Intelligence - Unpacking Racial Bias — An EI Workshop Report</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" type="text/css" href="/theme/css/bulma.css?1" />
        <link rel="stylesheet" type="text/css" href="/theme/css/main.css?4" />
    



    <meta name="description" content="As part of the wider Building Ethical Intelligence educational series, last week EI hosted a virtual workshop on AI & Racial Bias with Renée Cummings." />

    <meta name="tags" content="ethics" />
    <meta name="tags" content="racial bias" />
    <meta name="tags" content="workshops" />


<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@ethicalai_co" />
<meta name="twitter:title" content="Unpacking Racial Bias — An EI Workshop Report" />
<meta name="twitter:description" content="As part of the wider Building Ethical Intelligence educational series, last week EI hosted a virtual workshop on AI & Racial Bias with Renée Cummings." />
<meta name="twitter:image" content="https://pbs.twimg.com/profile_images/1189881071296536576/0G0jlH06_400x400.jpg" />


</head>

<body id="index" class="racial-bias-renee-cummings">
        
    <section class="hero is-fullheight is-default is-bold" id="nav_wrapper">
        <div class="hero-head">
            <nav class="navbar is-fixed-top">
                <div class="container">
                    <div class="navbar-brand">
                                <a class="navbar-item" href="/">
                                <img src="/theme/images/logo_small.png" alt="EI: ai ethics" />
                              </a>

                        
                        <span class="navbar-burger burger" data-target="navbarMenu">
                            <span></span>
                            <span></span>
                            <span></span>
                        </span>
                    </div>
                    <div id="navbarMenu" class="navbar-menu">
                        <div class="navbar-end">
                            <div class="tabs is-right">
                                <ul>
                                    <li  ><a href="/">Home</a></li>
                                    <li  ><a href="/pages/covid-19">COVID-19</a></li>
                                    <li  ><a href="/pages/about-us">About</a></li>
                                    <li  ><a href="/pages/experts">Experts</a></li>
                                    <li  ><a href="/pages/services">Services</a></li>
                                    <li><a href="http://course.ethicalintelligence.co"> Courses</a></li>
                                    <li  ><a href="/pages/case-studies">Case Studies</a></li>
                                    <li  ><a href="/blog_index">Blog</a></li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </nav>
        </div>

<div class="container">
    
    <div class="columns">
        
  
      <section id="content" class="body post-body column is-three-fifths is-offset-one-fifth">

    
        
    



  <header>
    
      <div class="ei-section-header alt blog">
    <h1 class="blog-item-heading">
      <a href="/racial-bias-renee-cummings.html" rel="bookmark"
         title="Permalink to Unpacking Racial Bias — An EI Workshop Report">Unpacking Racial Bias — An EI Workshop Report</a></h1>

      <address class="vcard author">
        By             <a class="url fn" href="/author/ei-team.html">EI-Team</a>
      </address>

         </div>
 
  </header>
  
  <div class="entry-content"><br>
    <h2>“Why let the new technology reinforce old biases?" - Renée Cummings, CEO of Urban AI</h2>
<p>As part of the wider Building Ethical Intelligence educational series, last week EI hosted a virtual workshop on AI &amp; Racial Bias with Renée Cummings. Designed to create a space for open conversation on the topic of systematic racism and how it has been reinforced in technology, the workshop consisted of a presentation by Renée, group discussions, and a wider conversation to reflect on potential points of action. </p>
<p>Additionally, we were joined by the co-founders of the <a href="https://www.radicalai.org/">Radical AI Podcast</a> who recorded Renée’s talk for a bonus episode. You can listen to the episode on <a href="https://podcasts.apple.com/us/podcast/the-radical-ai-podcast/id1505229145">iTunes</a>, <a href="https://open.spotify.com/episode/2qJIrocZHfLuZ0rNXOSF6d">Spotify</a> and <a href="https://radicalai.podbean.com/">Podbean</a>.</p>
<h2>Understanding Sentiment: A glance into how we perceive racial bias</h2>
<p>At the beginning of the workshop we asked participants to complete a survey about their attitude towards racial bias in tech. In total, we received 43 responses (after removing those who opted out of being reported). 58% of participants were female, 37% male, and 2% identified as non-binary. The participant’s professional background was varied but predominantly academic and from the tech industry. Finally, the participants were from all over the world but the United Kingdom and the United States were the most common countries. As far as the ethnic background of the participants, the biggest group identified as caucasian forming 41.9% of the participants. Black participants made up around 14% of the group, followed by Asian/Pacific Islander (9%). A significant portion of the participants (23.3%) identified as “Other”. In the following sections we will group together all people of colour (POC) as we have only a small number of participants in each group although the majority of participants were not caucasian. </p>
<div style="text-align:center"><img src="./images/Racial_Bias_Report/Figure_1.png" alt="Ethnic background of participants." width="500"/>
</div>

<p><em>Figure 1: Breakdown of participant's ethnicities.</em></p>
<p>To begin with, we asked participants to what degree they felt impacted by racial bias in technology. Their responses are shown in Figure 2. Overall we can see that POC tend to find that racial bias in technology impacts them, although the difference with caucasian participants is relatively small. The majority of participants across the board feel that racial bias in tech has a small to moderate impact on their lives.</p>
<p><img alt="To what extent do you feel impacted by racial bias in tech?" src="./images/Racial_Bias_Report/Figure_2.png">
<em>Figure 2: Participants’ responses to the question “to what degree do you feel impacted by racial bias in technology?” from 1 (Not at all) to 5 (Very) in percentage terms, according to ethnicity. Note that we group POC as each subpopulation in our sample is small.</em></p>
<p>Next we asked participants to what degree they felt they had the ability to mitigate racial bias in tech. Their answers are shown in Figure 3. The overwhelming majority of participants felt that they had little or no ability to mitigate racial bias in tech. This stands in contrast with the professional background of the participants, a lot of whom worked in technology, academia and law.</p>
<p><img alt="To what extent do you feel impacted by racial bias in tech?" src="./images/Racial_Bias_Report/Figure_3.png">
<em>Figure 3: Participants’ responses to the question “to what degree do you feel you have the ability to mitigate racial bias in technology within your daily life?” in percentage terms, according to ethnicity.</em></p>
<p>Finally in Figure 4 we show the participants’ attitude towards their own responsibility when it comes to fighting bias in tech. From this chart we can see minimal differences across ethnic groups as most participants feel they do have a responsibility to tackle bias in tech. Given that the majority of participants said they felt they didn’t have the ability to mitigate racial bias in tech, and yet simultaneously felt the responsibility to enact some kind of change, we can start to recognise a potential blocker in the fight against racial bias. Intention is the first step towards change, but knowing what steps to take to bring about that change is just as vital. With this in mind, we focused the breakout group discussions on practical steps to identifying racial bias in tech, as well as how to mitigate once identified. </p>
<p><img alt="To what extent do you feel impacted by racial bias in tech?" src="./images/Racial_Bias_Report/Figure_4.png">
<em>Figure 4: Participants’ responses to the question “to what degree do you feel you have a responsibility to fight racial bias in technology?” in percentage terms, according to ethnicity.</em></p>
<h2>Identifying systematic racism in our technology</h2>
<p><em>Technology is not just a mirror of existing biases, it is a magnifying glass.</em></p>
<p>Due to the influence and reach of our current technological systems, any implicit bias that slips into a system is immediately emphasized and amplified far beyond original intention. What we need to recognise, however, is that bias is not only a dataset problem and adding more data points will not result magically in a solution. Although bias is often found and mitigated on a dataset level, it extends beyond such into areas like data labeling, the deployment cycle, and design decisions. </p>
<p>One of the difficulties we face in fighting racial bias is the fact that machines and algorithms create a proxy that blocks the view of those being impacted by a system from being seen by the system’s creators. Although a system’s creator may have no intention of creating a racially biased system, if they are unable to see how their decisions have led to significant impact on individual people’s lives, it becomes difficult to feel accountable for negative outcomes and take into consideration impact on communities one is not a part of. </p>
<p>We have been able to identify and work on eliminating the vividly clear instances of racial bias, but this is only scratching the surface. Now we are faced with identifying the nuances in our technology, the magnifying glass of societal systems, in which deeply rooted systemic racism hides. Although it is essential that we thoroughly examine and question our technology, from datasets to algorithms all the way to development cycles, we must first begin by examining our societies from a human-centric perspective. </p>
<h2>How to impact technology for good</h2>
<p>So, where do we begin? </p>
<p>As we saw from the results of the survey, even though we may feel a strong sense of responsibility to impact a change in racial bias, that doesn’t necessarily mean we know how to or even feel that we have the ability to do so. Awareness of the issue is a vital first step, but what comes after? </p>
<p>For those in leadership positions, a good next step involves an active search for diverse employment tools and application protocols. We need to not only bring the right voices to the table, but also to make sure those voices have a microphone to speak into. It doesn’t matter how diverse a board is if the key voices do not have any power to impact. </p>
<p>For those who feel they have no power to impact, learn to trust in the strength of asking the right questions. Often, people from a non technical background feel they do not have the ability to question technology, as it is too far outside of their scope of knowledge. The longer we feed into this misconception, the harder it will be to overcome these issues. At the root of it all, these are human-based issues that impact people, which means if you are human you have a right and responsibility to question any technology. </p>
<p>Finally, for everyone, look to educate yourself and those around you. Consumers need to understand where, how and when AI is used in decision making so that they can make informed decisions about using, or not using, certain technology. Awareness, both in the tech industry and the wider public, starts with proper education and understanding. </p>
<p>Change is never comfortable. If we are to push forward, we must proceed with empathy, compassion, honesty. But most importantly, we must proceed loudly, for the time of silence is long gone.</p>
  </div><!-- /.entry-content -->

  <!--<footer class="post-info full">
      <time class="published" datetime="2020-06-29T15:00:00+02:00">
        Mon 29 June 2020
      </time>
      
      <address class="vcard author">
        By             <a class="url fn" href="/author/ei-team.html">EI-Team</a>
      </address>
      <div class="category">
          Category: <a href="/category/articles.html">articles</a>
      </div>
      <div class="tags">
          Tags:
              <a href="/tag/ethics.html">ethics</a>
              <a href="/tag/racial-bias.html">racial bias</a>
              <a href="/tag/workshops.html">workshops</a>
      </div>
    </footer>--><!-- /.post-info -->

</section>


</div><!-- /container -->
</div><!-- /container -->

        <div class="container post-index">
        <div class="featured_footer">
            <h2>AI Ethics is essential to sustainable tech innovation</h2>
            <p>Enroll in EI's Putting Ethics Into Action: A Beginner's Guide to AI and Big Data Ethics and start building your ethical intelligence today </p>
            <a href="https://lnkd.in/dbbmQh3">Learn More</a>
        </div>
        </div>
        
        <div class="hero-foot">
            <div class="footer-block">
                <div class="columns">
                    <div class="column is-half">
                        <h3>Connect With Us</h3>
                        <p class="fineprint">Subscribe to our newsletter for brief email updates on AI ethics issues</p>
                        <div class="contacts">
                            <a href="https://twitter.com/ethicalai_co"><img src="/theme/images/twl.png" /></a>
                            <a href="https://www.linkedin.com/company/ethical-intelligence-associates-limited/"><img src="/theme/images/li_logo.png" /></a>
                            <a href="mailto:info@ethicalintelligence.co?subject=Contact Request"><img src="/theme/images/mail.svg" /></a>
                        </div>
                        <p class="fineprint">© 2020 Ethical Intelligence Associates, Limited</p>
                        
                        
                    </div>


                  

                    <div class="column is-half">
                        <form method="post" class="subscribe-form" action="https://ethicalintelligence.us3.list-manage.com/subscribe/post?u=dd737100fcf5113f365d7c24c&amp;id=db5647864a">
                            <div class="fields"> 
                                <input type="text" name="FNAME" class="text" placeholder="Name" />
                                <input type="email" class="text" name="EMAIL" placeholder="Email" />
                            </div>
                            <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_dd737100fcf5113f365d7c24c_db5647864a" tabindex="-1" value=""></div>
                            <input name="subscribe" class="submit" type="submit" title="submit" value=">" />
                        </form>
                    </div>


                </div><!--/columns-->
            </div><!--/footer-block-->
        </div><!--/hero-foot-->


        
    </section>
    <script src="/theme/js/bulma.js?8"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-152792174-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());
 gtag('config', 'UA-152792174-1');
</script>



</html>
