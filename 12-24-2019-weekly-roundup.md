Title: Weekly AI Ethics News Roundup: Dec 17-24
SubTitle: Dec 17 - 24
Date: 2019-12-24 09:20
Modified: 2019-12-24 09:20
Category: news
Tags: roundup
Slug: ai-ethics-news-roundup-dec17-dec24
Authors: EI-Team
Template: roundup
Summary: Weekly AI Ethics News Roundup: Dec 17 - Dec 24

Welcome to the EI weekly round-up; a curation of quality posts to help you cut through the noise and get right to the heart of the discussion on AI and Tech Ethics.



## A great tweet from Arvind Narayanan

[Arvind Narayanan](https://twitter.com/random_walker) writes:

"If you think there's too much yelling about algorithmic bias, here's an analogy. By the mid 90s the privacy community knew there was a huge problem. But it took two decades of yelling and a million privacy disasters before the public and policy makers started taking it seriously."

<a class="readmore" href="https://twitter.com/random_walker/status/1208050796476215296">Read More</a>

## Persons yet Unknown: Animals, Chimeras, Artificial Intelligence and Beyond

[Kate Darling](https://twitter.com/grok_) and [Paresh Kathrani](https://twitter.com/PKathrani) in an fascinating discussion of robotics and AI and The Animal Law Conference. 

<a class="readmore" href="https://www.youtube.com/watch?v=dEFI05Gtalc">Read More</a>

## Implementing Ethics Into Artificial Intelligence: A Contribution, From A Legal Perspective, To The Development Of An Ai Governance Regime

This is a new article added to a great issue of the Duke Law and Technology Review that came out in August, a [Symposium for John Perry Barlow](https://scholarship.law.duke.edu/dltr/vol18/iss1/). 

"This Article advocates for the need to conduct in-depth risk-benefit-assessments with regard to the use of AI and autonomous systems. This Article points out major concerns in relation to AI and autonomous systems such as likely job losses, causation of damages, lack of transparency, increasing loss of humanity in social relationships, loss of privacy and personal autonomy, potential information biases and the error proneness, and susceptibility to manipulation of AI and autonomous systems. "

<a class="readmore" href="https://scholarship.law.duke.edu/dltr/vol18/iss1/17/">Read More</a>

## Researchers were about to solve AI’s black box problem, then the lawyers got involved

When things go wrong and AI runs amok, the lawyers will be there to tell us the most company-friendly version of what happened. Most importantly, they’ll protect companies from having to share how their AI systems work.

We’re trading a technical black box for a legal one. Somehow, this seems even more unfair.

<a class="readmore" href="https://thenextweb.com/artificial-intelligence/2019/12/17/researchers-were-about-to-solve-ais-black-box-problem-then-the-lawyers-got-involved/">Read More</a>


## Explainability and Adversarial Robustness for RNNs

"Since traditional evaluation metrics such as accuracy are not sufficient for quantifying the adversarial threat, we propose the Adversarial Robustness Score (ARS) for comparing IDSs, capturing a common notion of adversarial robustness, and show that an adversarial training procedure can significantly and successfully reduce the attack surface."

<a class="readmore" href="https://deepai.org/publication/explainability-and-adversarial-robustness-for-rnns">Read More</a>

## This AI researcher is trying to ward off a reproducibility crisis

Joelle Pineau doesn’t want science’s reproducibility crisis to come to artificial intelligence (AI).

<a class="readmore" href="https://www.nature.com/articles/d41586-019-03895-5">Read More</a>

## Ethics In AI: Why Values For Data Matter 

An argument for better corporate governance around AI and data. Corporations should "treat data as an asset .... the same way organizations treat inventory, fleet, and manufacturing assets. "

<a class="readmore" href="https://www.forbes.com/sites/sap/2019/12/18/ethics-in-ai/#2d7dd5285af4">Read More</a>

## The Virtuous Circle of Trusted AI: Turning Ethical and Transparent AI Into a Competitive Advantage


"Most large organizations today across the United States and Europe are talking about “duty of care” and AI (i.e. the duty to take care to refrain from causing another person injury or loss). We also hear a lot about the need for clear normative frameworks in areas such as driverless cars, drones, facial recognition, and algorithmic decisionmaking guidelines in public-facing services such as banking or retail. I shall be surprised if we will have this conversation again in two years’ time and legislation hasn’t already been seriously discussed or put in place."



<a class="readmore" href="https://www.capgemini.com/research/the-virtuous-circle-of-trusted-ai-turning-ethical-and-transparent-ai-into-a-competitive-advantage-luciano-floridi/">Read More</a>