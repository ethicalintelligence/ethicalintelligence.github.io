<!DOCTYPE html>
<html lang="en">
<head>
        
        <link rel="apple-touch-icon" sizes="57x57" href="/extra/apple-icon-57x57.png">
        <link rel="apple-touch-icon" sizes="60x60" href="/extra/apple-icon-60x60.png">
        <link rel="apple-touch-icon" sizes="72x72" href="/extra/apple-icon-72x72.png">
        <link rel="apple-touch-icon" sizes="76x76" href="/extra/apple-icon-76x76.png">
        <link rel="apple-touch-icon" sizes="114x114" href="/extra/apple-icon-114x114.png">
        <link rel="apple-touch-icon" sizes="120x120" href="/extra/apple-icon-120x120.png">
        <link rel="apple-touch-icon" sizes="144x144" href="/extra/apple-icon-144x144.png">
        <link rel="apple-touch-icon" sizes="152x152" href="/extra/apple-icon-152x152.png">
        <link rel="apple-touch-icon" sizes="180x180" href="/extra/apple-icon-180x180.png">
        <link rel="icon" type="image/png" sizes="192x192"  href="/extra/android-icon-192x192.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/extra/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="96x96" href="/extra/favicon-96x96.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/extra/favicon-16x16.png">
        <link rel="manifest" href="/extra/manifest.json">
        <meta name="msapplication-TileColor" content="#ffffff">
        <meta name="msapplication-TileImage" content="/extra/ms-icon-144x144.png">
        <meta name="theme-color" content="#ffffff">
        
        <link href="https://fonts.googleapis.com/css?family=Oswald:400,500,600,700&display=swap" rel="stylesheet">        
        <link href="https://fonts.googleapis.com/css?family=Nunito&display=swap" rel="stylesheet">
    
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        
          <title>Ethical Intelligence - Weekly AI Ethics News Roundup: Dec 2 - Dec 9</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" type="text/css" href="/theme/css/bulma.css" />
        <link rel="stylesheet" type="text/css" href="/theme/css/main.css?5" />
    
        <link href="/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Ethical Intelligence Full Atom Feed" />
        <link href="/feeds/news.atom.xml" type="application/atom+xml" rel="alternate" title="Ethical Intelligence Categories Atom Feed" />




    <meta name="tags" content="roundup" />

</head>

<body id="index" class="ai-ethics-news-roundup-dec-9">
        
    <section class="hero is-fullheight is-default is-bold" id="nav_wrapper">
        <div class="hero-head">
            <nav class="navbar is-fixed-top">
                <div class="container">
                    <div class="navbar-brand">
                                <a class="navbar-item" href="/">
                                <img src="/theme/images/logo_small.png" alt="EI: ai ethics" />
                              </a>

                        
                        <span class="navbar-burger burger" data-target="navbarMenu">
                            <span></span>
                            <span></span>
                            <span></span>
                        </span>
                    </div>
                    <div id="navbarMenu" class="navbar-menu">
                        <div class="navbar-end">
                            <div class="tabs is-right">
                                <ul>
                                    <li  ><a href="/">Home</a></li>
                                    <li  ><a href="/pages/about-us">About</a></li>
                                    <li  ><a href="/pages/experts">Experts</a></li>
                                    <li  ><a href="/pages/services">Services</a></li>
                                    <li  ><a href="/pages/case-studies">Case Studies</a></li>
                                    <li  ><a href="/blog_index">Blog</a></li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </nav>
        </div>

<div class="container">
    
    <div class="columns">
        
  
      <section id="content" class="body post-body column is-three-fifths is-offset-one-fifth">

    
        
    



  <header>
    
      <div class="ei-section-header alt blog">
    <h1 class="blog-item-heading">
      <a href="/ai-ethics-news-roundup-dec-9.html" rel="bookmark"
         title="Permalink to Weekly AI Ethics News Roundup: Dec 2 - Dec 9">Weekly AI Ethics News Roundup: Dec 2 - Dec 9</a></h1>

      <address class="vcard author">
        By             <a class="url fn" href="/author/ei-team.html">EI-Team</a>
      </address>

         </div>
 
  </header>
  
  <div class="entry-content">
    <p>Welcome to the EI weekly round-up; a curation of quality posts to help you cut through the noise and get right to the heart of the discussion on AI and Tech Ethics.</p>
<h2><a href="https://arxiv.org/abs/1912.00761">On the Legal Compatibility of Fairness Definitions</a></h2>
<p>Although the article was on arxiv last week, the author publicized it this week, and it's a good one. There's poor alignment between operationalized definitions of fairness in machine learning and the legal definitions that may in fact apply to the deployment of these systems. </p>
<p>"Past literature has been effective in demonstrating ideological gaps in machine learning (ML) fairness definitions when considering their use in complex socio-technical systems. However, we go further to demonstrate that these definitions often misunderstand the legal concepts from which they purport to be inspired, and consequently inappropriately co-opt legal language. In this paper, we demonstrate examples of this misalignment and discuss the differences in ML terminology and their legal counterparts, as well as what both the legal and ML fairness communities can learn from these tensions. We focus this paper on U.S. anti-discrimination law since the ML fairness research community regularly references terms from this body of law."</p>
<h2><a href="https://www.benzevgreen.com/wp-content/uploads/2019/11/19-ai4sg.pdf">'Good' isn’t good enough</a></h2>
<p>A critical reflection on the problems that arise when the pursuit of good is taken on as a technical objective too hastily, and why sustained and rigorous ethical reflection is a necessary if we want to have any confidence that such efforts will actually succeed. </p>
<p>"Despite widespread enthusiasm among computer scientists to contribute to “socialgood,” the field’s efforts to promote good lack a rigorous foundation in politicsor social change. There is limited discourse regarding what “good” actuallyentails, and instead a reliance on vague notions of what aspects of society aregood or bad. Moreover, the field rarely considers the types of social changethat result from algorithmic interventions, instead following a “greedy algorithm”approach of pursuing technology-centric incremental reform at all points."</p>
<h2><a href="https://medium.com/arthur-ai/uk-gpdr-watchdog-says-explain-your-ai-373ef76d3c">New guidelines on the GDPR Right to Explanation</a></h2>
<p>The UK’s Data Protection Authority just issued much-anticipated guidance that clarifies the complicated issue of the GDPR’s ‘right to explanation’. Here is some background on the issue and what the new information means.</p>
<h2><a href="https://www.linkedin.com/pulse/ethics-objective-reid-blackman-ph-d-/?trackingId=B5NT8Dd1BMx16FH15vHvZQ%3D%3D">Ethics is Objective</a></h2>
<p>Here are three arguments for the idea that ethics is subjective, presented with thoughtful rebuttals. This is a theme we took up in our last bog post, where we argued that there is a very large chunk of territory in tech ethics where ethical imperatives can be uncovered and agreed upon by sincere inquiry, even by those who disagree on more fundamental ethical and moral questions. </p>
<h2><a href="https://www.academia.edu/41168605/Online_information_of_vaccines_information_quality_is_an_ethical_responsibility_of_search_engines">Online information of vaccines: information quality is an ethical responsibility of search engines</a></h2>
<p>When health-related disinformation is available online, who is responsible? There's a growing backlash against the idea of platforms as "mere tools", but perhaps we should think the same of search engines. We don't usually think that a library is responsible for dangerous information in its books, but should we think differently about Google?</p>
<h2><a href="https://deepai.org/publication/recovering-from-biased-data-can-fairness-constraints-improve-accuracy">Recovering from Biased Data: Can Fairness Constraints Improve Accuracy?</a></h2>
<p>Multiple fairness constraints have been proposed in the literature, motivated by a range of concerns about how demographic groups might be treated unfairly by machine learning classifiers. In this work we consider a different motivation; learning from biased training data. </p>
<h2><a href="https://policyreview.info/concepts/datafication">Datafication</a></h2>
<p>In the course of researching and discussing AI ethics challenges, we might run across the claim while the rate and scope of our generation of data has increased, it can be understood on a continuum with the ways in which human activity have always left traces and records. This article on the concept of "datafication" argues against this, and shows several ways to understand what is distinctive about the new systems and actors that collect and use our data. </p>
<p>"Datafication is not just the making of information, which, in one sense, human beings have been doing since the creation of symbols and writing. Rather, datafication is a contemporary phenomenon which refers to the quantification of human life through digital information, very often for economic value. This process has major social consequences. Disciplines such as political economy, critical data studies, software studies, legal theory, and—more recently— decolonial theory, have considered different aspects of those consequences to be important. Fundamental to all such approaches is the analysis of the intersection of power and knowledge. "</p>
<h2><a href="https://www.techuk.org/insights/news/item/16447-welcome-to-techuk-digital-ethics-week">This is techUK Digital Ethics Week</a></h2>
<h2><a href="https://www.thetimes.co.uk/article/amazon-ready-to-cash-in-on-free-access-to-nhs-data-bbzp52n5m">Amazon ready to cash in on free access to NHS data</a></h2>
  </div><!-- /.entry-content -->

  <footer class="post-info full">
      <time class="published" datetime="2019-12-09T09:20:00+01:00">
        Mon 09 December 2019
      </time>
      
      <address class="vcard author">
        By             <a class="url fn" href="/author/ei-team.html">EI-Team</a>
      </address>
      <div class="category">
          Category: <a href="/category/news.html">news</a>
      </div>
      <div class="tags">
          Tags:
              <a href="/tag/roundup.html">roundup</a>
      </div>
    </footer><!-- /.post-info -->

</section>
</div><!-- /container -->
</div><!-- /container -->
        
        <div class="hero-foot">
            <div class="footer-block">
                <div class="columns">
                    <div class="column is-half">
                        <h3>Connect With Us</h3>
                        <p class="fineprint">Subscribe to our newsletter for brief email updates on AI ethics issues</p>
                        <div class="contacts">
                            <a href="https://twitter.com/ethicalai_co"><img src="/theme/images/twl.png" /></a>
                            <a href="https://www.linkedin.com/company/ethical-intelligence-associates-limited/"><img src="/theme/images/li_logo.png" /></a>
                            <a href="mailto:info@ethicalintelligence.co?subject=Contact Request"><img src="/theme/images/mail.svg" /></a>
                        </div>
                        <p class="fineprint">© 2019 Ethical Intelligence Associates, Limited</p>
                        
                        
                    </div>


                  

                    <div class="column is-half">
                        <form method="post" class="subscribe-form" action="https://ethicalintelligence.us3.list-manage.com/subscribe/post?u=dd737100fcf5113f365d7c24c&amp;id=db5647864a">
                            <div class="fields"> 
                                <input type="text" name="FNAME" class="text" placeholder="Name" />
                                <input type="email" class="text" name="EMAIL" placeholder="Email" />
                            </div>
                            <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_dd737100fcf5113f365d7c24c_db5647864a" tabindex="-1" value=""></div>
                            <input name="subscribe" class="submit" type="submit" title="submit" value=">" />
                        </form>
                    </div>


                </div>
            </div>
        </div>
    </section>
    <script src="/theme/js/bulma.js"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-152792174-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());
 gtag('config', 'UA-152792174-1');
</script>

</body>

</html>
