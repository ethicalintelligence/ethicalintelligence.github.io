Title: Weekly AI Ethics News Roundup: March 31 - April 7
SubTitle: Mar 31 - Apr 7
Date: 2020-04-07 09:20
Modified: 2020-04-07 09:20
Category: news
Tags: roundup
Slug: ai-ethics-news-roundup-apr7-2020
Authors: EI-Team
Template: roundup
Summary: @ds_wats0n and @Floridi on interpretable #machinelearning, @christianmunthe on moral agency, @_KarenHao AI predicting life outcomes for children, @gabrielazanfir on data protection, @AFCEA on intelligent weapons, @VincentCMueller with an SEP entry on AI ethics + more


Welcome to the EI weekly round-up; a curation of quality posts to help you cut through the noise and get right to the heart of the discussion on AI and Tech Ethics.

Every Tuesday we publish a list of links to articles and debates that have happened over the past week in the community, allowing you to stay as up-to-date as possible on developments and facts. We will often link to arguments from all sides of the debate, even if the opinions may be controversial. We would like to mention, however, that EI does not endorse any of the information published, all links are reflections of the author's opinions and not that of Ethical Intelligence.


## How artificial intelligence and machine learning are used in hiring and recruiting

"Job seekers interact more with advancing tech than they realize as more companies turn to automated tools in talent acquisition."

<a class="readmore" href="https://www.zdnet.com/article/how-artificial-intelligence-and-machine-learning-are-used-in-hiring-and-recruiting/">Read More</a>



## AI in the headlines: the portrayal of the ethical issues of artificial intelligence in the media


"This paper expands upon previous research by systematically analyzing and categorizing the media portrayal of the ethical issues of AI to better understand how media coverage of these issues may shape public debate about AI. Our results suggest that the media has a fairly realistic and practical focus in its coverage of the ethics of AI, but that the coverage is still shallow. A multifaceted approach to handling the social, ethical and policy issues of AI technology is needed, including increasing the accessibility of correct information to the public in the form of fact sheets and ethical value statements on trusted webpages (e.g., government agencies), collaboration and inclusion of ethics and AI experts in both research and public debate, and consistent government policies or regulatory frameworks for AI technology."

There's also a [nice article about this piece](https://news.ncsu.edu/2020/04/how-we-write-about-ai-ethics/)

And [an interview](https://www.futurity.org/artificial-intelligence-news-coverage-ethics-2326172/)!

"A recent analysis of how journalists deal with the ethics of artificial intelligence suggests that reporters are doing a good job of grappling with a complex set of questions—but there’s room for improvement."


<a class="readmore" href="https://link.springer.com/article/10.1007/s00146-020-00965-5">Read More</a>



## AI can’t predict how a child’s life will turn out even with a ton of data


"Hundreds of researchers attempted to predict children’s and families’ outcomes, using 15 years of data. None were able to do so with meaningful accuracy."

<a class="readmore" href="https://www.technologyreview.com/s/615434/ai-machine-learning-social-outcome-prediction-study/?utm_medium=tr_social&utm_campaign=site_visitor.unpaid.engagement&utm_source=Twitter#Echobox=1586185183">Read More</a>


## Why data protection law is uniquely equipped to let us fight a pandemic with personal data

"Data protection law is different than “privacy”. We, data protection lawyers, have been complacent recently and have failed to clarify this loud and clear for the general public. Perhaps happy to finally see this field of law taking the front stage of public debate through the GDPR, we have not stopped anyone from saying that the GDPR is a privacy law." 

<a class="readmore" href="https://pdpecho.com/2020/04/06/why-data-protection-law-is-uniquely-equipped-to-let-us-fight-a-pandemic-with-personal-data/">Read More</a>

## It's Time to Take Seriously the Machine Ethics of Autonomous and AI Cyber Systems 

"Many concepts revolve around the law of armed conflict, societal law, ethical dilemmas, psychological concepts and artificially intelligent cyber systems, as well as their relationships among each other. In addition to the delineation of machine ethic guidelines, an ethical life cycle is necessary to account for changes over time in national circumstances and personal beliefs. Just recently, the Defense Innovation Board, which serves as an advisory board to the Pentagon, met and published ethical guidelines in designing and implementing artificially intelligent weapons. Artificial intelligence (AI) systems in the Defense Department must satisfy the conditions of responsibility, equitability, traceability, reliability and governability. The Defense Innovation Board approved five ethical principles."

<a class="readmore" href="https://www.afcea.org/content/its-time-take-seriously-machine-ethics-autonomous-and-ai-cyber-systems">Read More</a>


## AI Ethics - From Principles to Practice

"We have prepared this report as experts in spheres ranging from computer science, philosophy, and technology impact assessment via physics and engineering to social sciences, and we work together as the AI Ethics Impact Group (AIEI Group). Our paper offers concrete guidance to decision-makers in organisations developing and using AI on how to incorporate values into algorithmic decision-making, and how to measure the fulfilment of values using criteria, observables and indicators combined with a context-dependent risk assessment. "

<a class="readmore" href="https://www.ai-ethics-impact.org/resource/blob/1961130/c6db9894ee73aefa489d6249f5ee2b9f/aieig---report---download-hb-data.pdf">Read More</a>

## A Normative Approach to Artificial Moral Agency


"This paper proposes a methodological redirection of the philosophical debate on artificial moral agency (AMA) in view of increasingly pressing practical needs due to technological development. This “normative approach” suggests abandoning theoretical discussions about what conditions may hold for moral agency and to what extent these may be met by artificial entities such as AI systems and robots. Instead, the debate should focus on how and to what extent such entities should be included in human practices normally assuming moral agency and responsibility of participants"

<a class="readmore" href="https://www.researchgate.net/publication/311196481_A_Normative_Approach_to_Artificial_Moral_Agency">Read More</a>


## Ethics of Artificial Intelligence and Robotics

A new Stanford Encyclopedia of Philosophy entry in on the way!

"Artificial intelligence (AI) and robotics are digital technologies that will be of major importance for the development of humanity in the near future. They have raised fundamental questions about what we should do with these systems, what the systems themselves should do, what risks they involve and how we can control these. After the Introduction to the field (1), the main themes of this article are: (2) Ethical issues that arise with AI systems as objects, i.e. tools made and used by humans; here, the main sections are privacy and manipulation, opacity and bias, human-robot interaction, employment, and the effects of autonomy. (3) AI systems as subjects, i.e. when ethics is for the AI systems themselves in machine ethics and artificial moral agency. (4) The problem of a possible future AI superintelligence leading to a ‘singularity’. For each section within these themes, we provide a general explanation of the ethical issues, we outline existing positions and arguments, then we analyse how this plays out with current technologies and finally what policy consequences may be drawn"

<a class="readmore" href="https://philarchive.org/archive/MLLEOA-4">Read More</a>



## The explanation game: a formal framework for interpretable machine learning

"We propose a formal framework for interpretable machine learning. Combining elements from statistical learning, causal interventionism, and decision theory, we design an idealised explanation game in which players collaborate to find the best explanation(s) for a given algorithmic prediction. "

<a class="readmore" href="https://link.springer.com/article/10.1007/s11229-020-02629-9?wt_mc=Internal.Event.1.SEM.ArticleAuthorOnlineFirst&utm_source=ArticleAuthorOnlineFirst&utm_medium=email&utm_content=AA_en_06082018&ArticleAuthorOnlineFirst_20200404">Read More</a>

