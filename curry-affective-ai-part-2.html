<!DOCTYPE html>
<html lang="en">
<head>
        
        <link rel="apple-touch-icon" sizes="57x57" href="/extra/apple-icon-57x57.png">
        <link rel="apple-touch-icon" sizes="60x60" href="/extra/apple-icon-60x60.png">
        <link rel="apple-touch-icon" sizes="72x72" href="/extra/apple-icon-72x72.png">
        <link rel="apple-touch-icon" sizes="76x76" href="/extra/apple-icon-76x76.png">
        <link rel="apple-touch-icon" sizes="114x114" href="/extra/apple-icon-114x114.png">
        <link rel="apple-touch-icon" sizes="120x120" href="/extra/apple-icon-120x120.png">
        <link rel="apple-touch-icon" sizes="144x144" href="/extra/apple-icon-144x144.png">
        <link rel="apple-touch-icon" sizes="152x152" href="/extra/apple-icon-152x152.png">
        <link rel="apple-touch-icon" sizes="180x180" href="/extra/apple-icon-180x180.png">
        <link rel="icon" type="image/png" sizes="192x192"  href="/extra/android-icon-192x192.png">
        <link rel="icon" type="image/png" sizes="32x32" href="/extra/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="96x96" href="/extra/favicon-96x96.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/extra/favicon-16x16.png">
        <link rel="manifest" href="/extra/manifest.json">
        <meta name="msapplication-TileColor" content="#ffffff">
        <meta name="msapplication-TileImage" content="/extra/ms-icon-144x144.png">
        <meta name="theme-color" content="#ffffff">
        
        <link href="https://fonts.googleapis.com/css?family=Oswald:400,500,600,700&display=swap" rel="stylesheet">        
        <link href="https://fonts.googleapis.com/css?family=Nunito&display=swap" rel="stylesheet">
    
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        
          <title>Ethical Intelligence - Affective Video Technology and the Ethics of Flawed Scientific Foundations –Part II</title>
        <meta charset="utf-8" />
        <link rel="stylesheet" type="text/css" href="https://ethicalintelligence.co/theme/css/bulma.css?1" />
        <link rel="stylesheet" type="text/css" href="https://ethicalintelligence.co/theme/css/main.css?1" />
    



    <meta name="description" content="Hundreds of companies are not using affective video technology during the hiring process but the ethical ramifications of this technology have not been fully fleshed out." />

    <meta name="tags" content="ethics" />
    <meta name="tags" content="affective AI" />
    <meta name="tags" content="emotion AI" />
    <meta name="tags" content="privacy" />
    <meta name="tags" content="bias" />

 
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ethicalintelligence.co/curry-affective-ai-part-2.html" />
<meta property="og:title" content="Affective Video Technology and the Ethics of Flawed Scientific Foundations –Part II" />
<meta property="og:description" content="Hundreds of companies are not using affective video technology during the hiring process but the ethical ramifications of this technology have not been fully fleshed out." />
<meta property="og:image" content="https://ethicalintelligence.co/images/ogp_images/affective-tech-pt2.jpg" />


<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@ethicalai_co" />
<meta name="twitter:title" content="Affective Video Technology and the Ethics of Flawed Scientific Foundations –Part II" />
<meta name="twitter:description" content="Hundreds of companies are not using affective video technology during the hiring process but the ethical ramifications of this technology have not been fully fleshed out." />
<meta name="twitter:image" content="https://ethicalintelligence.co/images/ogp_images/affective-tech-pt2.jpg" />


</head>

<body id="index" class="curry-affective-ai-part-2">
        
    <section class="hero is-fullheight is-default is-bold" id="nav_wrapper">
        <div class="hero-head">
            <nav class="navbar is-fixed-top">
                <div class="container">
                    <div class="navbar-brand">
                                <a class="navbar-item" href="/">
                                <img src="/theme/images/logo_small.png" alt="EI: ai ethics" />
                              </a>

                        
                        <span class="navbar-burger burger" data-target="navbarMenu">
                            <span></span>
                            <span></span>
                            <span></span>
                        </span>
                    </div>
                    <div id="navbarMenu" class="navbar-menu">
                        <div class="navbar-end">
                            <div class="tabs is-right">
                                <ul>
                                    <li  ><a href="/">Home</a></li>
                                    <li  ><a href="/pages/covid-19">COVID-19</a></li>
                                    <li  ><a href="/pages/about-us">About</a></li>
                                    <li  ><a href="/pages/experts">Experts</a></li>
                                    <li  ><a href="/pages/services">Services</a></li>
                                    <li><a href="http://course.ethicalintelligence.co"> Courses</a></li>
                                    <li  ><a href="/pages/case-studies">Case Studies</a></li>
                                    <li  ><a href="/blog_index">Blog</a></li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </nav>
        </div>

<div class="container">
    
    <div class="columns">
        
  
      <section id="content" class="body post-body column is-three-fifths is-offset-one-fifth">

    
        
    



  <header>
    
      <div class="ei-section-header alt blog">
    <h1 class="blog-item-heading">
      <a href="https://ethicalintelligence.co/curry-affective-ai-part-2.html" rel="bookmark"
         title="Permalink to Affective Video Technology and the Ethics of Flawed Scientific Foundations –Part II">Affective Video Technology and the Ethics of Flawed Scientific Foundations –Part II</a></h1>
         <h3>Thursday 16 July 2020</h3>
      <address class="vcard author">
        By             <a class="url fn" href="https://ethicalintelligence.co/author/alba-curry.html">Alba Curry</a>
      </address>
      

         </div>
 
  </header>
  
  <div class="entry-content"><br>
    <p>In Part I, I discussed widely held concerns over the use of affective video technology such as bias and privacy, to which HireVue has responded in their website. The only concern that is not addressed in their website, although it has come under some scrutiny by both the <a href="https://www.theguardian.com/technology/2019/mar/06/facial-recognition-software-emotional-science">media</a> and <a href="https://ainowinstitute.org/AI_Now_2019_Report.pdf">AI Now in their 2019 report</a>, is the claim that it is based on outdated scientific knowledge. Meredith Whittaker, a co-founder of the AI Now Institute, called HireVue’s practices pseudoscience and a license to discriminate. <a href="https://www.washingtonpost.com/technology/2019/10/22/ai-hiring-face-scanning-algorithm-increasingly-decides-whether-you-deserve-job/">HireVue’s CTO called the criticism uninformed</a>, defending that “most AI researchers have a limited understanding” of the psychology behind how workers think and behave. Nonetheless, even if AI researchers are not IO psychology experts, HireVue’s critics are basing their criticisms on sound scientific evidence which their own so-called psychology experts are ignoring. </p>
<p>The field of science of emotion for the purposes of this critique can be divided into two camps: those following the “common view”, started by Paul Ekman in the 60s, and those following more recent exhaustive studies with Lisa F. Barret as their main advocate. The common view, on which Affective Video technology is based, presupposes 1) that certain emotion categories are routinely expressed by a unique facial configuration and 2) people can reliably infer emotional states from a set of facial movements. Lisa F. Barret and critics of Affective AI technology have tested both assumptions in a recent <a href="https://journals.sagepub.com/eprint/SAUES8UM69EN8TSMUGF9/full">journal article</a> and find evidence for neither. </p>
<p>HireVue uses reverse inference to assess something about a person’s emotional state that is not directly accessible: They claim to identify emotions based on their correlation with facial configurations. For this correlation to be valid it needs to occur more often than by chance. To then make reverse inference about a person’s emotional state through conditional probability, <a href="https://journals.sagepub.com/na101/home/literatum/publisher/sage/journals/content/psia/2019/psia_20_1/1529100619832930/20191106/images/large/10.1177_1529100619832930-table2.jpeg">four criteria</a> must be met: reliability, specificity, generalizability, and validity:</p>
<ol>
<li>
<p><strong>Reliability</strong>: whether a scowl can be statistically said to correlate with anger or not. For this we need to know whether anger and a scowl come together often enough. Studies suggest that people sometimes scowl in anger, but not always above chance level. Self-reported anger may also occur without a scowl, making this inference hardly reliable. </p>
</li>
<li>
<p><strong>Specificity</strong>: To infer emotions from facial configurations these must be unique to a specific emotion. However Barret’s review looking at facial configurations, voice, physical symptoms and brain activity found that there are no facial configurations, or combinations, unique to any emotion. </p>
</li>
<li>
<p><strong>Generalizability</strong>: This criteria involves at least two things, whether the scientific findings can be replicated in the real world, and whether or not they apply to non-Western and minority populations. The outcomes of studies for the generalizability of facial expressions is not robust. </p>
</li>
<li>
<p><strong>Validity</strong>: This criteria remains a difficult and unanswered question since it involves being able to demonstrate objectively that even if there was a strong generalizability the person is truly experiencing the emotion. In other words, we need to have a way to verify that the person we are perceiving to be angry is truly angry. </p>
</li>
</ol>
<p>Three out of these four criteria have limited conclusions (reliability, specificity, and generalizability), and we are yet to find a way to show the validity of the studies. Only when a pattern of facial muscle movements strongly satisfies these four criteria can we justify calling it an “emotional expression.” Scientists do agree that facial movements convey a range of information and are important for social communication, but Barret et al’s review suggests that the assumptions on which affective video technology are based are fragile and barely supported. </p>
<p>In other words, the available scientific evidence suggests that people sometimes smile when happy or frown when sad, as proposed by the common view, but how emotions are communicated can vary substantially across cultures, situations or people and “facial expressions” can express instances of different emotions. In fact, a given configuration of facial movements, such as a scowl, often communicates something other than an emotional state.</p>
<p>Whether or not we find Barret et al’s analysis of findings and their own research conclusive or not, they show enough evidence that none of the ideas behind current affective video technology stand up to scientific scrutiny. Affective video technology relies on commonplace understandings of emotions which are neither scientifically nor philosophically reliable. Because the views are still so commonplace, however, they go largely unexamined in the enthusiastic rush towards new tech, all the while yielding social harms: real human beings have their careers thwarted based on the misguided belief that we can simplistically measure human emotions in the face, body, or voice. No one would want to board a spaceship built on a pre-Galilean understanding of the universe, but this is precisely what over 700 companies have done, using HireVue technology. </p>
<h2>Recommendations and Conclusion</h2>
<p>Lisa F. Barret et al leave us with the following list of recommendations for further research:</p>
<ol>
<li>
<p>New research on emotion should consider sampling individuals deeply, with high dimensional measurements, across many different situations, times of day, and so forth: a Big Data approach to learning the expressive repertoires of individual people. The diagnosis of an instance of emotion might be improved by combining many features, even those that are weakly diagnostic on their own, particularly if the analysis is conducted in a person-specific (idiographic) way.</p>
</li>
<li>
<p>Only a highly multivariate set of measures is likely to work to classify instances of emotion with high reliability and specificity. This means looking at more than physical clues. In principle, rich, multimodal observations could be available from videos; when time-synchronized with the other physical measurements, such video could be extremely useful in understanding the conditions when certain facial movements are made and what those movements might mean in a given context. Naturally, Big Data in the absence of hypotheses is not necessarily helpful. (And this raises issues of privacy.) </p>
</li>
<li>
<p>Participants could be offered the opportunity to annotate their videos with subjective ratings of the features that describe their experiences (whether or not they are identified as emotions). Candidate features are affective properties such as valence and arousal, appraisals (i.e., descriptions of how a situation is experienced), and emotion-related goals. These additional psychological features have the potential to add higher dimensional details to more specifically characterize facial movements and what they mean. Such an approach introduces various technical and modeling challenges, but this sort of deeply inductive approach is now within reach.</p>
</li>
</ol>
<p>Although affective video technology is not necessarily a dead-end project, it has a long way to go before it is ethically viable since it cannot even do what it purports to do. Understanding how to, and whether it is even possible, to infer someone’s emotional state or predict someone’s future actions from their facial movements is not yet within reach. Furthermore, given the fact that this affects in real, tangible ways, the lives of individuals and society as a whole it is unethical and irresponsible to claim to offer those services now. Its major impediment is the science behind it, but it also needs to answer the important concerns regarding privacy and how to best avoid recreating societies’s biases and potentially creating new ones. </p>
  </div><!-- /.entry-content -->

  <!--<footer class="post-info full">
      <time class="published" datetime="2020-07-16T17:00:00+02:00">
        Thu 16 July 2020
      </time>
      
      <address class="vcard author">
        By             <a class="url fn" href="https://ethicalintelligence.co/author/alba-curry.html">Alba Curry</a>
      </address>
      <div class="category">
          Category: <a href="https://ethicalintelligence.co/category/articles.html">articles</a>
      </div>
      <div class="tags">
          Tags:
              <a href="https://ethicalintelligence.co/tag/ethics.html">ethics</a>
              <a href="https://ethicalintelligence.co/tag/affective-ai.html">affective AI</a>
              <a href="https://ethicalintelligence.co/tag/emotion-ai.html">emotion AI</a>
              <a href="https://ethicalintelligence.co/tag/privacy.html">privacy</a>
              <a href="https://ethicalintelligence.co/tag/bias.html">bias</a>
      </div>
    </footer>--><!-- /.post-info -->

</section>


</div><!-- /container -->
</div><!-- /container -->

        <div class="container post-index">
        <div class="featured_footer">
            <h2>AI Ethics is essential to sustainable tech innovation</h2>
            <p>Enroll in EI's Putting Ethics Into Action: A Beginner's Guide to AI and Big Data Ethics and start building your ethical intelligence today </p>
            <a href="https://lnkd.in/dbbmQh3">Learn More</a>
        </div>
        </div>
        
        <div class="hero-foot">
            <div class="footer-block">
                <div class="columns">
                    <div class="column is-half">
                        <h3>Connect With Us</h3>
                        <p class="fineprint">Subscribe to our newsletter for brief email updates on AI ethics issues</p>
                        <div class="contacts">
                            <a href="https://twitter.com/ethicalai_co"><img src="/theme/images/twl.png" /></a>
                            <a href="https://www.linkedin.com/company/ethical-intelligence-associates-limited/"><img src="/theme/images/li_logo.png" /></a>
                            <a href="mailto:info@ethicalintelligence.co?subject=Contact Request"><img src="/theme/images/mail.svg" /></a>
                        </div>
                        <p class="fineprint">© 2020 Ethical Intelligence Associates, Limited</p>
                        
                        
                    </div>


                  

                    <div class="column is-half">
                        <form method="post" class="subscribe-form" action="https://ethicalintelligence.us3.list-manage.com/subscribe/post?u=dd737100fcf5113f365d7c24c&amp;id=db5647864a">
                            <div class="fields"> 
                                <input type="text" name="FNAME" class="text" placeholder="Name" />
                                <input type="email" class="text" name="EMAIL" placeholder="Email" />
                            </div>
                            <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_dd737100fcf5113f365d7c24c_db5647864a" tabindex="-1" value=""></div>
                            <input name="subscribe" class="submit" type="submit" title="submit" value=">" />
                        </form>
                    </div>


                </div><!--/columns-->
            </div><!--/footer-block-->
        </div><!--/hero-foot-->


        
    </section>
    <script src="/theme/js/bulma.js?8"></script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-152792174-1"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());
 gtag('config', 'UA-152792174-1');
</script>



</html>
