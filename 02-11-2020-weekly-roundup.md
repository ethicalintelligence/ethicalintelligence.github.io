Title: Weekly AI Ethics News Roundup: Feb 5 - Feb 11
SubTitle: Feb 5 - Feb 11
Date: 2020-02-11 09:20
Modified: 2020-02-11 09:20
Category: news
Tags: roundup
Slug: ai-ethics-news-roundup-feb5-feb11-2020
Authors: EI-Team
Template: roundup
Summary: @alexsablay and @hjegou on tracking training data, @dorotheabaur on facial recognition, @lindakinstler on tech ethicists, @benzevenbergen and @drzimmermann on ethical pitfalls, SyRI from @SaschaSchendel, @datainnovation 2019 review, @PublicStandards report on AI

Welcome to the EI weekly round-up; a curation of quality posts to help you cut through the noise and get right to the heart of the discussion on AI and Tech Ethics.

Every Tuesday we publish a list of links to articles and debates that have happened over the past week in the community, allowing you to stay as up-to-date as possible on developments and facts. We will often link to arguments from all sides of the debate, even if the opinions may be controversial. We would like to mention, however, that EI does not endorse any of the information published, all links are reflections of the author's opinions and not that of Ethical Intelligence.


## European parliament says it will not use facial recognition tech

"The European parliament has insisted it has no plans to introduce facial recognition technology after a leaked internal memo discussing its use in security provoked an outcry."

<a class="readmore" href="https://www.theguardian.com/technology/2020/feb/05/european-parliament-insists-it-will-not-use-facial-recognition-tech">Read More</a>


## The SyRI case: a landmark ruling for benefits claimants around the world

"In NJCM cs/ De Staat der Nederlanden (NJCM vs the Netherlands), also known as the SyRI case, the court considered the legality of the System Risk Indication (SyRI), a system designed by the Dutch government to process large amounts of data collected by various Dutch public authorities to identify those most likely to commit benefits fraud."

There's a [great twitter thread on SyRI too](https://twitter.com/SaschaSchendel/status/1225094322510536705)


<a class="readmore" href="https://privacyinternational.org/news-analysis/3363/syri-case-landmark-ruling-benefits-claimants-around-world?PageSpeed=noscript">Read More</a>


## Using ‘radioactive data’ to detect if a data set was used for training

"We have developed a new technique to mark the images in a data set so that researchers can determine whether a particular machine learning model has been trained using those images. This can help researchers and engineers to keep track of which data set was used to train a model so they can better understand how various data sets affect the performance of different neural networks."

<a class="readmore" href="https://arxiv.org/abs/2002.00937">Read More</a>


## Opposing facial recognition — why focusing on accuracy misses the point


"These are important and very worrying findings that emphasize the overall problem with algorithmic discrimination. But what does it imply when we argue against facial technology based on empirical arguments such as overall low accuracy and particular bias with regards to certain ethnic groups? In the worst case, proponents of facial recognition could use this argument to their advantage and take it to underline the need to train the technology better to make sure it improves its accuracy — as apparently done by Google last year. Better training means collecting more data. And collecting more data often means intruding into people’s privacy. We might open the floodgates for even larger scale data collection."

<a class="readmore" href="https://medium.com/@dorotheabaur/opposing-facial-recognition-why-focusing-on-accuracy-misses-the-point-9b96ea3f864b">Read More</a>


## An Algorithm That Grants Freedom, or Takes It Away

"Across the United States and Europe, software is making probation decisions and predicting whether teens will commit crime. Opponents want more human oversight."


<a class="readmore" href="https://www.nytimes.com/2020/02/06/technology/predictive-algorithms-crime.html?referringSource=articleShare
">Read More</a>


## Ethicists were hired to save tech’s soul. Will anyone let them?

 "While some tech firms have taken concrete steps to insert ethical thinking into their processes, Catherine Miller, interim CEO of the ethical consultancy Doteveryone, says there's also been a lot of "flapping round" the subject."

"Critics dismiss it as "ethics-washing," the practice of merely kowtowing in the direction of moral values in order to stave off government regulation and media criticism. The term belongs to the growing lexicon around technology ethics, or "tethics," an abbreviation that began as satire on the TV show "Silicon Valley," but has since crossed over into occasionally earnest usage. "

<a class="readmore" href="https://www.protocol.com/ethics-silicon-valley">Read More</a>


## AIES '20: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society

"As AI (and associated AI-hype) grows more pervasive in our lives, its impact on society is ever more significant, raising ethical concerns and challenges regarding issues such as privacy, safety and security, surveillance, inequality, data handling and bias, personal agency, power relations, effective modes of regulation, accountability, sanctions, and workforce displacement. Only a multidisciplinary effort can find the best ways to address these concerns, including experts from various disciplines, such as ethics, philosophy, economics, sociology, psychology, law, history, politics, interaction design, informatics, social studies of science and technology, communication and media studies, and political science, as well as those with lived experience in relation to the impacts of AI systems. In order to address these issues in a scientific context, AAAI and ACM joined forces in 2018 to start the AAAI/ACM Conference on AI, Ethics, and Society. "

<a class="readmore" href="https://dl.acm.org/doi/proceedings/10.1145/3375627#sec1">Read More</a>


## AI Ethics: Seven Traps

"The question of how to ensure that technological innovation in machine learning and artificial intelligence leads to ethically desirable—or, more minimally, ethically defensible—impacts on society has generated much public debate in recent years. Most of these discussions have been accompanied by a strong sense of urgency: as more and more studies about algorithmic bias have shown, the risk that emerging technologies will not only reflect, but also exacerbate structural injustice in society is significant."

  
<a class="readmore" href="https://freedom-to-tinker.com/2019/03/25/ai-ethics-seven-traps/">Read More</a>


## Artificial Intelligence and Public Standards: Committee publishes report   

“Our message to government is that the UK’s regulatory and governance framework for AI in the public sector remains a work in progress and deficiencies are notable. The work of the Office for AI, the Alan Turing Institute, the Centre for Data Ethics and Innovation (CDEI), and the Information Commissioner’s Office (ICO) are all commendable. But on transparency and data bias in particular, there is an urgent need for practical guidance and enforceable regulation."

<a class="readmore" href="https://www.gov.uk/government/news/artificial-intelligence-and-public-standards-committee-publishes-report">Read More</a>


## The Most Significant AI Policy Developments in the United States in 2019

"2019 was a monumental year for artificial intelligence (AI) policy in the United States. The federal government took several important steps that prioritized AI development and deployment and positioned the United States to strengthen its global AI leadership, beginning with President Trump’s “Executive Order on Maintaining American Leadership in Artificial Intelligence,” which set the tone for the rest of the year."

<a class="readmore" href="https://www.datainnovation.org/2020/02/the-most-significant-ai-policy-developments-in-the-united-states-in-2019/">Read More</a>


