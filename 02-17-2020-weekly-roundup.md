Title: Weekly AI Ethics News Roundup: Feb 12 - Feb 18
SubTitle: Feb 12 - Feb 18
Date: 2020-02-18 09:20
Modified: 2020-02-18 09:20
Category: news
Tags: roundup
Slug: ai-ethics-news-roundup-feb2-feb18-2020
Authors: EI-Team
Template: roundup
Summary: History of algorithms w/ @RiederB,@silvertjeand,@_mstevenson, @dorotheabaur finds a dilemma for companies ethics-washing facial recognition, @_KarenHao on OpenAI, @chengela and @hannahdev on reading emotion, @poppynoor on medtech, and @emilymbender tweeting from AAAS2020


Welcome to the EI weekly round-up; a curation of quality posts to help you cut through the noise and get right to the heart of the discussion on AI and Tech Ethics.

Every Tuesday we publish a list of links to articles and debates that have happened over the past week in the community, allowing you to stay as up-to-date as possible on developments and facts. We will often link to arguments from all sides of the debate, even if the opinions may be controversial. We would like to mention, however, that EI does not endorse any of the information published, all links are reflections of the author's opinions and not that of Ethical Intelligence.


## Emotion AI researchers say overblown claims give their work a bad name

There are no strong, peer-reviewed studie proving that analyzing body posture or facial expressions can help pick the best workers or students (in part because companies are secretive about their methods). As a result, the hype around emotion recognition, which is projected to be a $25 billion market by 2023, has created a backlash from tech ethicists and activists who fear that the technology could raise the same kinds of discrimination problems as predictive sentencing or housing algorithms for landlords deciding whom to rent to.


<a class="readmore" href="https://www.technologyreview.com/s/615232/ai-emotion-recognition-affective-computing-hirevue-regulation-ethics/?utm_source=newsletters&utm_medium=email&utm_campaign=the_algorithm.unpaid.engagement">Read More</a>

## Why we should hope that corporate claims about the ethics of facial recognition are pure marketing


"If we acknowledge the non-commercial, or rather the effectively ‘far-beyond-commercial’ dimensions of facial recognition technology, we in fact severely restrict our abilities to demand accountability for the claims regarding their ‘ethical qualities’."

<a class="readmore" href="https://medium.com/@dorotheabaur/why-we-should-hope-that-corporate-claims-about-the-ethics-of-facial-recognition-are-pure-marketing-d8b2fea83319">Read More</a>


## The historical trajectories of algorithmic techniques: an interview with Bernhard Rieder

"In this interview, Michael Stevenson (MS) and Anne Helmond (AH) talk to Bernhard Rieder (BR) about his forthcoming book entitled Engines of Order: A Mechanology of Algorithmic Techniques (University of Amsterdam Press, 2020). In particular, Rieder discusses how the practice of software-making is “constantly faced with the ‘legacies’ of previous work” and how the past continues to operate into present algorithmic techniques."

<a class="readmore" href="https://www.tandfonline.com/doi/full/10.1080/24701475.2020.1723345">Read More</a>

## We know ethics should inform AI. But which ethics?

The ethical standards for assessing AI and its associated technologies are still in their infancy. Companies need to initiate internal discussion as well as external debate with their key stakeholders about how to avoid being caught up in difficult situations.

<a class="readmore" href="https://www.gigabitmagazine.com/ai/we-know-ethics-should-inform-ai-which-ethics?utm_content=117506893&utm_medium=social&utm_source=twitter&hss_channel=tw-2797602696">Read More</a>

## Navigating AI’s expanding role in the world of HR

As the use of artificial intelligence continues to skyrocket within the HR realm, related ethics issues represent real risk if not handled correctly, and early. 

<a class="readmore" href="https://hrexecutive.com/navigating-ais-expanding-role-in-the-world-of-hr/">Read More</a>

## The messy, secretive reality behind OpenAI’s bid to save the world

Karen Hao spent half a year digging into @OpenAI, the SF-based AI research lab, originally founded by @elonmusk. I started with a few simple questions: Who are they? What are their goals? How do they work? After nearly three dozen interviews, I found so much more.

<a class="readmore" href="https://www.technologyreview.com/s/615181/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/">Read More</a>

## "AI systems claiming to 'read' emotions pose discrimination risks

There are no strong, peer-reviewed studie proving that analyzing body posture or facial expressions can help pick the best workers or students (in part because companies are secretive about their methods). As a result, the hype around emotion recognition, which is projected to be a $25 billion market by 2023, has created a backlash from tech ethicists and activists who fear that the technology could raise the same kinds of discrimination problems as predictive sentencing or housing algorithms for landlords deciding whom to rent to.


<a class="readmore" href="https://www.theguardian.com/technology/2020/feb/16/ai-systems-claiming-to-read-emotions-pose-discrimination-risks">Read More</a>

## Can we trust AI not to further embed racial bias and prejudice?

Heralded as an easy fix for health services under pressure, data technology is marching ahead unchecked But is there a risk it could compound inequalities? Poppy Noor investigates


<a class="readmore" href="https://www.bmj.com/content/368/bmj.m363">Read More</a>

## Great twitter thread from the Ethics and AI panel panel at American Association for the Advancement of Science 2020

<a class="readmore" href="https://twitter.com/emilymbender/status/1228749166622334976">Read More</a>

